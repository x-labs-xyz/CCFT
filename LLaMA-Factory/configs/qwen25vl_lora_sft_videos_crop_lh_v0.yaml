### model
model_name_or_path: /home/hao/CCFT/Qwen2.5-VL/Qwen2.5-VL-7B-Instruct # 模型的路径，指定你自己的模型路径。如果你有自定义模型，这里需要改成相应的路径。
trust_remote_code: true
flash_attn: fa2

### method
stage: sft # 指定训练阶段为 SFT（Supervised Fine-Tuning），这是一个监督微调的阶段。
do_train: true # 表示开始进行训练。
finetuning_type: lora # 使用 LoRA (Low-Rank Adaptation) 方法进行微调。建议避免使用 QLoRA 等其他复杂微调方法，因为 LoRA 效率更高且较为简单。
lora_target: all # 这里指定所有的模型层都将被 LoRA 处理，确保微调应用到整个模型。
#lora_target: q_proj, k_proj, v_proj
#deepspeed: configs/deepspeed/ds_z3_config.json  # 这个是很猛的降低显存的办法，我加的！！！记住，这么加就行！！！
#lora_rank: 256 # 数据多就多给点
#lora_alpha: 256 # 数据多就多给点

### dataset
dataset: CCFT_havid_sub_videos_crop_lh_v0_cot # 使用的数据集。这里包含两个数据集：mllm_demo 和 identity。你可以使用这些默认数据集或者替换成自己的数据集。
template: qwen2_vl # 数据集的模板，用于定义如何处理输入和输出。
cutoff_len: 5120 # 输入文本的最大长度，超过这个长度的文本将被截断。
max_samples: 100000 # 最多处理的数据样本数量，这里限制为 1000 样本。
overwrite_cache: true # 是否覆盖预处理的数据缓存。如果之前缓存有数据，这里会强制覆盖。
preprocessing_num_workers: 128 # 数据预处理时使用的 CPU 核心数量，指定为 16 个核心以加速处理。

### output
output_dir: saves/Qwen2.5-VL-7B-Instruct/lora/CCFT_havid_sub_videos_crop_lh_v0_cot # 训练输出的保存路径，所有训练结果将保存到这个目录。可以根据需要修改此路径。
logging_steps: 1 # 每隔 10 步进行一次日志记录，方便跟踪训练进度。
save_steps: 100 # 每 500 步保存一次模型检查点，确保可以在训练中途恢复。
plot_loss: true # 是否绘制损失曲线，开启此选项可以帮助你可视化训练损失的变化。
overwrite_output_dir: true # 是否覆盖之前的输出目录，如果之前有训练结果，这里会将其覆盖。
#save_total_limit: 2

### train
per_device_train_batch_size: 1 # 每个设备（如 GPU）上的训练批次大小为 1，适合显存有限的设备。
gradient_accumulation_steps: 1 # 梯度累积步数为 8，这意味着每 8 个小批次的梯度将累积后再进行一次更新，等效于增加了有效批次大小。
learning_rate: 1.0e-4 # 学习率设置为 1.0e-4，这是一个较小的学习率，适合微调任务。
num_train_epochs: 12 # 训练的总轮数为 ，数据量多的话可以适当增加训练轮次。官方示例中默认使用 3 轮。
lr_scheduler_type: cosine # 使用余弦学习率调度器，学习率将根据余弦函数逐渐减少。
warmup_ratio: 0.1 # 热身比例为 0.1，这意味着前 10% 的训练步骤用于热身，逐渐增大学习率。
bf16: true  # 使用 bf16 混合精度训练，能够在不损失太多精度的情况下加速训练。
ddp_timeout: 180000000 # DDP（分布式数据并行）超时设置，确保在分布式环境下不会因为超时导致训练中断。

### eval
do_eval: false
val_size: 0.1 # 验证集占数据集的比例为 0.1，表示使用 10% 的数据集进行验证。
per_device_eval_batch_size: 1 # 每个设备上评估的批次大小为 1，与训练的批次大小一致。
eval_strategy: steps # 评估策略为按步评估，意味着每隔一定步数进行一次评估。
eval_steps: 100 # 每 500 步进行一次评估，确保训练期间可以监控模型性能。

